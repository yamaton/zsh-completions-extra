#compdef fairseq-validate

# Auto-generated with h2o

function _fairseq-validate {
    _arguments \
        {-h,--help}'[show this help message and exit]' \
        '--no-progress-bar[disable progress bar]' \
        '--log-interval[log progress every N batches (when progress bar is disabled)]' \
        '--log-format[log format to use]' \
        '--log-file[log file to copy metrics to.]':file:_files \
        '--aim-repo[path to Aim repository]' \
        '--aim-run-hash[Aim run hash. If skipped, creates or continues run based on save_dir]' \
        '--tensorboard-logdir[path to save logs for tensorboard, should match --logdir of running tensorboard (default: no tensorboard logging)]':file:_files \
        '--wandb-project[Weights and Biases project name to use for logging]' \
        '--azureml-logging[Log scalars to AzureML context]' \
        '--seed[pseudo random number generator seed]' \
        '--cpu[use CPU instead of CUDA]' \
        '--tpu[use TPU instead of CUDA]' \
        '--bf16[use bfloat16; implies --tpu]' \
        '--memory-efficient-bf16[use a memory-efficient version of BF16 training; implies --bf16]' \
        '--fp16[use FP16]' \
        '--memory-efficient-fp16[use a memory-efficient version of FP16 training; implies --fp16]' \
        '--fp16-no-flatten-grads[don'\''t flatten FP16 grads tensor]' \
        '--fp16-init-scale[default FP16 loss scale]' \
        '--fp16-scale-window[number of updates before increasing loss scale]' \
        '--fp16-scale-tolerance[pct of updates that can overflow before decreasing the loss scale]' \
        '--on-cpu-convert-precision[if set, the floating point conversion to fp16/bf16 runs on CPU. This reduces bus transfer time and GPU memory usage.]' \
        '--min-loss-scale[minimum FP16/AMP loss scale, after which training is stopped]' \
        '--threshold-loss-scale[threshold FP16 loss scale from below]' \
        '--amp[use automatic mixed precision]' \
        '--amp-batch-retries[number of retries of same batch after reducing loss scale with AMP]' \
        '--amp-init-scale[default AMP loss scale]' \
        '--amp-scale-window[number of updates before increasing AMP loss scale]' \
        '--user-dir[path to a python module containing custom extensions (tasks and/or architectures)]':file:_files \
        '--empty-cache-freq[how often to clear the PyTorch CUDA cache (0 to disable)]' \
        '--all-gather-list-size[number of bytes reserved for gathering stats from workers]' \
        '--model-parallel-size[total number of GPUs to parallelize model over]' \
        '--quantization-config-path[path to quantization config file]':file:_files \
        '--profile[enable autograd profiler emit_nvtx]' \
        '--reset-logging[when using Hydra, reset the logging at the beginning of training]' \
        '--suppress-crashes[suppress crashes when training with the hydra_train entry point so that the main method can return a value (useful for sweeps)]' \
        '--use-plasma-view[Store indices and sizes in shared memory]' \
        '--plasma-path[path to run plasma_store, defaults to /tmp/plasma. Paths outside /tmp tend to fail.]':file:_files \
        {--criterion,--tokenizer,--bpe,--optimizer,--lr-scheduler,--scoring,--task}'[task]' \
        '--num-workers[how many subprocesses to use for data loading]' \
        '--skip-invalid-size-inputs-valid-test[ignore too long or too short lines in valid and test set]' \
        '--max-tokens[maximum number of tokens in a batch]' \
        {--batch-size,--max-sentences}'[number of examples in a batch]' \
        '--required-batch-size-multiple[batch size will be a multiplier of this value]' \
        '--required-seq-len-multiple[maximum sequence length in batch will be a multiplier of this value]' \
        '--dataset-impl[output dataset implementation]' \
        '--data-buffer-size[Number of batches to preload]' \
        '--train-subset[data subset to use for training (e.g. train, valid, test)]' \
        '--valid-subset[comma separated list of data subsets to use for validation (e.g. train, valid, test)]' \
        {--combine-valid-subsets,--combine-val}'[comma separated list of data subsets to use for validation (e.g. train, valid, test)]' \
        '--ignore-unused-valid-subsets[do not raise error if valid subsets are ignored]' \
        '--validate-interval[validate every N epochs]' \
        '--validate-interval-updates[validate every N updates]' \
        '--validate-after-updates[dont validate until reaching this many updates]' \
        '--fixed-validation-seed[specified random seed for validation]' \
        '--disable-validation[disable validation]' \
        '--max-tokens-valid[maximum number of tokens in a validation batch (defaults to --max-tokens)]' \
        {--batch-size-valid,--max-sentences-valid}'[batch size of the validation batch (defaults to --batch-size)]' \
        {--max-valid-steps,--nval}'[How many batches to evaluate]' \
        '--curriculum[don'\''t shuffle batches for first N epochs]' \
        '--gen-subset[data subset to generate (train, valid, test)]' \
        '--num-shards[shard generation over N shards]' \
        '--shard-id[id of the shard to generate (id < num_shards)]' \
        '--grouped-shuffling[shuffle batches in groups of num_shards to enable similar sequence lengths on each GPU worker when batches are sorted by length]' \
        '--update-epoch-batch-itr[if true then prevents the reuse the epoch batch iterator by setting can_reuse_epoch_itr to false, defaults to --grouped-shuffling )]' \
        '--update-ordered-indices-seed[if true then increment seed with epoch for getting batch iterators, defautls to False.]' \
        '--distributed-world-size[total number of GPUs across all nodes (default: all visible GPUs)]' \
        '--distributed-num-procs[total number of processes to fork (default: all visible GPUs)]' \
        '--distributed-rank[rank of the current worker]' \
        '--distributed-backend[distributed backend]' \
        '--distributed-init-method[typically tcp://hostname:port that will be used to establish initial connetion]' \
        '--distributed-port[port number (not required if using --distributed-init-method)]' \
        {--device-id,--local_rank}'[which GPU to use (by default looks for $LOCAL_RANK, usually configured automatically)]' \
        '--distributed-no-spawn[do not spawn multiple processes even if multiple GPUs are visible]' \
        '--ddp-backend[DistributedDataParallel backend]' \
        '--ddp-comm-hook[communication hook]' \
        '--bucket-cap-mb[bucket size for reduction]' \
        '--fix-batches-to-gpus[don'\''t shuffle batches between GPUs; this reduces overall randomness and may affect precision but avoids the cost of re-reading the data]' \
        '--find-unused-parameters[disable unused parameter detection (not applicable to --ddp-backend=legacy_ddp)]' \
        '--gradient-as-bucket-view[when set to True, gradients will be views pointing to different offsets of allreduce communication buckets. This can reduce peak memory usage, where the saved memory size will be equal to the total gradients size. --gradient-as-bucket-view=gradient_as_bucket_view)]' \
        '--fast-stat-sync[\[deprecated\] this is now defined per Criterion]' \
        '--heartbeat-timeout[kill the job if no progress is made in N seconds; set to -1 to disable]' \
        '--broadcast-buffers[Copy non-trainable parameters between GPUs, such as batchnorm population statistics]' \
        '--slowmo-momentum[SlowMo momentum term; by default use 0.0 for 16 GPUs, 0.2 for 32 GPUs; 0.5 for 64 GPUs, 0.6 for > 64 GPUs]' \
        '--slowmo-base-algorithm[Base algorithm. Either '\''localsgd'\'' or '\''sgp'\''. Please refer to the documentation of '\''slowmo_base_algorithm'\'' parameter in https://fairscale.readthedocs.io/en/latest/api/experimental/nn/slowmo_ddp.html for more details]' \
        '--localsgd-frequency[Local SGD allreduce frequency]' \
        '--nprocs-per-node[number of GPUs in each node. An allreduce operation across GPUs in a node is very fast. Hence, we do allreduce across GPUs in a node, and gossip across different nodes]' \
        '--pipeline-model-parallel[if set, use pipeline model parallelism across GPUs]' \
        '--pipeline-balance[partition the model into N_K pieces, where each piece contains N_i layers. The sum(args.pipeline_balance) should equal the total number of layers in the model]' \
        '--pipeline-devices[a list of device indices indicating which device to place each of the N_K partitions. The length of this list should equal the length of the --pipeline-balance argument]' \
        '--pipeline-chunks[microbatch count for pipeline model parallelism]' \
        '--pipeline-encoder-balance[partition the pipeline parallel encoder into N_K pieces, where each piece contains N_i layers. The sum(args.pipeline_encoder_balance) should equal the total number of encoder layers in the model]' \
        '--pipeline-encoder-devices[a list of device indices indicating which device to place each of the N_K partitions. The length of this list should equal the length of the --pipeline-encoder-balance argument]' \
        '--pipeline-decoder-balance[partition the pipeline parallel decoder into N_K pieces, where each piece contains N_i layers. The sum(args.pipeline_decoder_balance) should equal the total number of decoder layers in the model]' \
        '--pipeline-decoder-devices[a list of device indices indicating which device to place each of the N_K partitions. The length of this list should equal the length of the --pipeline-decoder-balance argument]' \
        '--pipeline-checkpoint[checkpointing mode for pipeline model parallelism]' \
        '--zero-sharding[ZeRO sharding]' \
        '--no-reshard-after-forward[don'\''t reshard parameters after forward pass]' \
        '--fp32-reduce-scatter[reduce-scatter grads in FP32]' \
        '--cpu-offload[offload FP32 params to CPU]' \
        '--use-sharded-state[use sharded checkpoint files]' \
        '--not-fsdp-flatten-parameters[not flatten parameter param for fsdp]' \
        '--path[path(s) to model file(s), colon separated]':file:_files \
        {--post-process,--remove-bpe}'[post-process text by removing BPE, letter segmentation, etc. Valid options can be found in fairseq.data.utils.post_process.]' \
        '--quiet[only print final scores]' \
        '--model-overrides[a dictionary used to override model args at generation that were used during model training]' \
        '--results-path[path to save eval results (optional)]':file:_files \
        "*: :_files"

}

_fairseq-validate "$@"

